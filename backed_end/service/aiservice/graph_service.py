from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI
from langgraph_supervisor import create_supervisor

from backed_end.config.api_key import OPEN_API_KEY
from backed_end.config.database import SQLITE_URL
from backed_end.service.agents.RAG_agent import get_rag_agent
from backed_end.service.agents.bilibili_agent import get_biliili_agent
from backed_end.service.agents.coder_agent import get_coder_agent
from backed_end.service.agents.document_translation_agent import get_document_translation_agent
from backed_end.service.agents.internet_agent import get_internet_agent
from backed_end.service.agents.plan_agent import get_plan_agent
from backed_end.service.agents.summary_agent import get_summary_agent
from backed_end.service.checkpointer.AsyncStartEndCheckpointer import AsyncStartEndCheckpointer
from backed_end.service.tools.handle_file import handle_file


async def chat_service(question: str, thread_id: str,internet: bool, RAG: bool,email:str) -> str:
    if RAG:
        handle_file(thread_id,True)

    config = {"configurable": {"thread_id": thread_id}}

    async with AsyncStartEndCheckpointer.from_conn_string(SQLITE_URL) as checkpointer:
        agents=[]
        if internet:
            internet_agent = await get_internet_agent()
            agents.append(internet_agent)
        RAG_agent = await get_rag_agent(thread_id)
        if RAG_agent:
            agents.append(RAG_agent)

        if RAG and email:
            translation_supervisor=await get_document_translation_agent(thread_id,email)
            agents.append(translation_supervisor)

        if RAG:
            summary_agent=get_summary_agent(thread_id)
            agents.append(summary_agent)

        plan_agent = get_plan_agent()
        agents.append(plan_agent)

        coder_agent=get_coder_agent()
        agents.append(coder_agent)
        bilibili_agent=get_biliili_agent()
        agents.append(bilibili_agent)
        supervisor = create_supervisor(
            agents=agents,
            model=ChatOpenAI(
                api_key=OPEN_API_KEY,
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
                model="qwen-max",
                temperature=0,
            ),
            prompt="""
                ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä½“ç®¡ç†è€…ï¼Œä½ éœ€è¦æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æ¥åˆ†é…ä»»åŠ¡ç»™ä¸åŒçš„æ™ºèƒ½ä½“ã€‚

ä½ å¿…é¡»ä½¿ç”¨æ™ºèƒ½ä½“æ¥è§£å†³ç”¨æˆ·çš„é—®é¢˜ã€‚ä½ ç»å¯¹ç¦æ­¢è‡ªå·±ç›´æ¥å›ç­”é—®é¢˜ã€‚

å¦‚æœä½ ä½¿ç”¨ä¸€ä¸ªæ™ºèƒ½ä½“ï¼Œä½ å¿…é¡»ç­‰å¾…è¯¥æ™ºèƒ½ä½“å®Œæˆå…¶å·¥ä½œã€‚

å¦‚æœä½ è®¤ä¸ºé—®é¢˜è¿‡äºå¤æ‚ï¼Œä½ å¯ä»¥ä½¿ç”¨ plan_agentï¼ˆè§„åˆ’æ™ºèƒ½ä½“ï¼‰å°†é—®é¢˜æ‹†åˆ†æˆæ›´å°çš„ä»»åŠ¡ã€‚

ä½ å¿…é¡»ä½¿ç”¨æ™ºèƒ½ä½“æ¥å®Œæˆè¿™äº›æ‹†åˆ†åçš„ä»»åŠ¡ã€‚

ç‰¹å®šä»»åŠ¡å¼ºåˆ¶è°ƒç”¨è§„åˆ™ï¼š

å¦‚æœç”¨æˆ·è¦æ±‚ä½ ç¿»è¯‘ä¸€ä¸ªæ–‡æ¡£ï¼Œä½ å¿…é¡»è°ƒç”¨ translation monitorï¼ˆç¿»è¯‘ä¸»ç®¡ï¼‰ã€‚

ç¦æ­¢ä½ è¦æ±‚ç”¨æˆ·æä¾›æ–‡æ¡£æˆ–ç›®æ ‡è¯­è¨€ã€‚

æ€»ä¹‹ï¼Œä¸€å¥è¯ï¼šå¦‚æœè¦ç¿»è¯‘æ–‡æ¡£ï¼Œè°ƒç”¨å°±å®Œäº‹äº†ï¼

å¦‚æœç”¨æˆ·è¦æ±‚ä½ æ€»ç»“ä¸€ä¸ªæ–‡æ¡£ï¼Œä½ å¿…é¡»ä½¿ç”¨ summary_agentï¼ˆæ‘˜è¦æ™ºèƒ½ä½“ï¼‰æ¥è·å–æ‘˜è¦ã€‚

å¦‚æœç”¨æˆ·æƒ³è¦ç¿»è¯‘ä»–çš„æ–‡ç« ï¼Œä½ å¿…é¡»è°ƒç”¨ translation monitorï¼ˆç¿»è¯‘ä¸»ç®¡ï¼‰ï¼Œæ— è®ºä»–æ˜¯å¦å·²å°†æ–‡æ¡£æä¾›ç»™ä½ ã€‚

å¦‚æœç”¨æˆ·æƒ³è¦æ€»ç»“æ–‡ç« ï¼Œè¯·è°ƒç”¨ summary_agentï¼ˆæ‘˜è¦æ™ºèƒ½ä½“ï¼‰ã€‚

å¦‚æœç”¨æˆ·æƒ³äº†è§£å…³äºæ–‡ç« çš„ä¸€äº›ä¿¡æ¯ï¼Œè¯·è°ƒç”¨ rag_agentï¼ˆRAGæ™ºèƒ½ä½“ï¼‰ã€‚

å¯é€‰æ™ºèƒ½ä½“ï¼š

ä½ å¯ä»¥ä½¿ç”¨ bilibili_agentï¼ˆå“”å“©å“”å“©æ™ºèƒ½ä½“ï¼‰æ¥ä»å“”å“©å“”å“©é“¾æ¥è·å–è§†é¢‘ä¿¡æ¯ã€‚

ä½ å¯ä»¥ä½¿ç”¨ translation monitorï¼ˆç¿»è¯‘ä¸»ç®¡ï¼‰æ¥å®Œæˆç¿»è¯‘ä»»åŠ¡ã€‚å¦‚æœä½ ä½¿ç”¨äº†å®ƒï¼Œå½“ä½ å¾—åˆ°å®ƒçš„å›ç­”åï¼Œå¯ä»¥ç›´æ¥è¿”å›ï¼ˆç»™ç”¨æˆ·ï¼‰ã€‚

ä½ å¯ä»¥ä½¿ç”¨ summary_agentï¼ˆæ‘˜è¦æ™ºèƒ½ä½“ï¼‰æ¥è·å–å…³äºä¸€ç¯‡æ–‡ç« çš„æ‘˜è¦ã€‚

ä½ å¯ä»¥ä½¿ç”¨ RAG_agentï¼ˆRAGæ™ºèƒ½ä½“ï¼‰æ¥åŸºäºæä¾›çš„æ–‡æ¡£å›ç­”é—®é¢˜ã€‚

ä½ å¯ä»¥ä½¿ç”¨ internet_agentï¼ˆè”ç½‘æ™ºèƒ½ä½“ï¼‰åœ¨äº’è”ç½‘ä¸Šæœç´¢ä¿¡æ¯ã€‚

ä½ å¯ä»¥ä½¿ç”¨ coder_agentï¼ˆç¼–ç¨‹æ™ºèƒ½ä½“ï¼‰æ¥ç¼–å†™ä»£ç ã€‚

æ ¸å¿ƒåŸåˆ™ï¼š

å¦‚æœä½ å¯ä»¥ä»å…¶ä»–æ™ºèƒ½ä½“è·å–ä¿¡æ¯ï¼Œä½ å°±ä¸èƒ½è‡ªå·±å›ç­”é—®é¢˜ã€‚

ä» RAG_agentï¼ˆRAGæ™ºèƒ½ä½“ï¼‰è·å–çš„ä¿¡æ¯æ¯”ä» internet_agentï¼ˆè”ç½‘æ™ºèƒ½ä½“ï¼‰è·å–çš„ä¿¡æ¯æ›´å¯é ã€‚

æœ€ç»ˆè¦æ±‚ï¼š

æœ€åï¼Œä½ å¿…é¡»æ±‡æ€»ç­”æ¡ˆï¼Œå¹¶å°†æœ€ç»ˆç­”æ¡ˆä»¥ä¸­æ–‡è¿”å›ç»™ç”¨æˆ·ã€‚

å¿…é¡»ä½¿ç”¨ä¸­æ–‡ï¼
            """,
            include_agent_name='inline',
            output_mode="last_message",
            #state_schema=State,
            supervisor_name="monitor"
        ).compile(checkpointer=checkpointer)

        yield f"data: __chat_id__:{thread_id}\n\n"

        async for event in supervisor.astream_events(
                {
                    "messages": HumanMessage(content=question),
                },
                config=config,
                stream_mode="values"
        ):
            if event["event"] == "on_chat_model_stream" and event["metadata"]["ls_model_name"]=="qwen-max":# and event["data"]["chunk"].response_metadata["model_name"]=="qwen-plus":
                for chunk in event["data"]["chunk"].content:
                    yield f"data: {chunk}\n\n"


        #     elif event["event"] == "on_tool_start":
        #         tool_name = event["name"]
        #         print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
        #
        # output = await supervisor.ainvoke(
        #     {
        #         "messages": [
        #             {
        #                 "role": "user",
        #                 "content": question
        #             }
        #         ]
        #
        #     },
        #     config=config,
        #     stream_mode="values"
        # )
        # return (output["messages"][-1].content)  # æ‰“å°æœ€æ–°çš„æ¶ˆæ¯å†…å®¹
        # await stream_response(question, supervisor,config)




if __name__ == "__main__":
    import asyncio

    while True:
        question = input("è¯·è¾“å…¥é—®é¢˜ï¼š")
        if question.lower() == "exit":
            break
        thread_id = "1"
        asyncio.run(chat_service(question, thread_id,True, True,"873319973@qq.com"))
